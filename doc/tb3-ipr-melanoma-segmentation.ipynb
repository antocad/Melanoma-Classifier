{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Auteur: Antoine Cadiou\n",
    "\n",
    "# Attention: pour fonctionner il faut récupérer les données sur ces liens: \n",
    "### https://www.kaggle.com/antocad/labels-siim-isic-224/settings\n",
    "### https://www.kaggle.com/arroqc/siic-isic-224x224-images\n",
    "### www.kaggle.com/dataset/2e87262f75481531a0ed807cfbe69fbb4ff7b43c39fc5b3a6c812bc27f026942\n",
    "#### et changer les chemins des données dans le code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, concatenate, Conv2D, MaxPooling2D, UpSampling2D, Reshape, core, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras import backend as K\n",
    "from keras.utils.vis_utils import plot_model as plot\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import *\n",
    "from keras.layers import *        \n",
    "from keras.applications.vgg16 import VGG16\n",
    "import keras\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, array_to_img, img_to_array\n",
    "from tensorflow.keras import datasets\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from keras.regularizers import l2\n",
    "from keras import optimizers, layers, regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "CFG = dict(\n",
    "    DEVICE = 'GPU',\n",
    "    \n",
    "    train_size = 0.8,\n",
    "    random_seed = 42, #None ou int\n",
    "    \n",
    "    img_size = 256,\n",
    "    epochs = 100,\n",
    "    batch_size = 32,\n",
    "    \n",
    "    lr_start = 0.000006,\n",
    "    lr_max = 0.00000145,\n",
    "    lr_min = 0.000001,\n",
    "    lr_rampup = 5,\n",
    "    lr_sustain = 0,\n",
    "    lr_decay = 0.85,\n",
    "    optimizer = 'adam',\n",
    "    label_smooth_fac  =   0.05,\n",
    "    \n",
    "    net_count = 1,\n",
    "    tta_steps = 1,\n",
    ")\n",
    "\n",
    "if CFG['DEVICE'] == \"TPU\":\n",
    "    print(\"connecting to TPU...\")\n",
    "    try:\n",
    "        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "        print('Running on TPU ', tpu.master())\n",
    "    except ValueError:\n",
    "        print(\"Could not connect to TPU\")\n",
    "        tpu = None\n",
    "\n",
    "    if tpu:\n",
    "        try:\n",
    "            print(\"initializing  TPU ...\")\n",
    "            tf.config.experimental_connect_to_cluster(tpu)\n",
    "            tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "            strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "            print(\"TPU initialized\")\n",
    "        except _:\n",
    "            print(\"failed to initialize TPU\")\n",
    "    else:\n",
    "        CFG['DEVICE'] = \"GPU\"\n",
    "\n",
    "if CFG['DEVICE'] != \"TPU\":\n",
    "    print(\"Using default strategy for CPU and single GPU\")\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "\n",
    "if CFG['DEVICE'] == \"GPU\":\n",
    "    print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "    \n",
    "\n",
    "AUTO     = tf.data.experimental.AUTOTUNE\n",
    "REPLICAS = strategy.num_replicas_in_sync\n",
    "print(f'REPLICAS: {REPLICAS}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#on lit les données csv\n",
    "train_original = pd.read_csv('../input/labels-siim-isic-224/train.csv', dtype=str)\n",
    "#on construit un dataframe réduit, plus équilibré\n",
    "part_true = train_original[train_original[\"target\"] == '1']\n",
    "part_false = train_original[train_original[\"target\"] == '0'].sample(len(part_true) * 3)\n",
    "train_balanced = pd.concat([part_true, part_false])\n",
    "#on shuffle les lignes du dataframe\n",
    "if CFG['random_seed']!=None:\n",
    "    np.random.seed(CFG['random_seed'])\n",
    "cols = train_balanced.columns\n",
    "idshuffle = np.arange(len(train_balanced))\n",
    "np.random.shuffle(idshuffle)\n",
    "df = pd.DataFrame(np.array(train_balanced)[idshuffle])\n",
    "df.columns = cols\n",
    "#on construit la colonne filename + nettoyage\n",
    "df['filename'] = df['image_name']+'.png'\n",
    "df['target'] = df['benign_malignant']\n",
    "df = df.drop(columns=['image_name', 'patient_id','sex','age_approx','anatom_site_general_challenge','diagnosis','benign_malignant'])\n",
    "df = df[['filename', 'target']]\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def dullrazor(img, lowbound=20, filterstruc=7, inpaintmat=3):\n",
    "    #grayscale\n",
    "    imgtmp1 = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    #applying a blackhat\n",
    "    filterSize =(filterstruc, filterstruc)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, filterSize) \n",
    "    imgtmp2 = cv2.morphologyEx(imgtmp1, cv2.MORPH_BLACKHAT, kernel)\n",
    "    #0=skin and 255=hair\n",
    "    ret, mask = cv2.threshold(imgtmp2, lowbound, 255, cv2.THRESH_BINARY)\n",
    "    #inpainting\n",
    "    img_final = cv2.inpaint(img, mask, inpaintmat ,cv2.INPAINT_TELEA)\n",
    "    return img_final\n",
    "\n",
    "def getSegmentation(img):\n",
    "    #gaussian filter\n",
    "    img = cv2.GaussianBlur(img,(7,7),0)\n",
    "    #gray threshold\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    ret, mask = cv2.threshold(gray,0,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "    #Morphological reconstruction\n",
    "    def morph(I, M):\n",
    "        struc = np.ones((3,3))\n",
    "        r = np.sum(I)\n",
    "        s = 0\n",
    "        while s != r:\n",
    "            s = r\n",
    "            dilated = ndimage.binary_dilation(M, structure=struc)\n",
    "            M = np.logical_and(I, dilated)\n",
    "            r = np.sum(M)\n",
    "        return M\n",
    "    M = np.zeros((CFG['img_size'], CFG['img_size']))\n",
    "    rond = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(101,101))\n",
    "    m = int(CFG['img_size']/2)\n",
    "    M[m-50:m+51, m-50:m+51] = rond\n",
    "    mask = morph(mask, M).astype('uint8')\n",
    "    # noise removal\n",
    "    kernel = np.ones((7,7),np.uint8)\n",
    "    mask = ndimage.binary_dilation(mask, structure=kernel)\n",
    "    mask = ndimage.binary_opening(mask, structure=np.ones((11,11),np.uint8))\n",
    "    return mask\n",
    "\n",
    "def preprocess(input_img):\n",
    "    img = (input_img.copy()).astype('uint8')\n",
    "    plt.imshow(img)\n",
    "    plt.title(\"image originale\")\n",
    "    plt.show()\n",
    "    # white balance for every channel independently\n",
    "    def wb(channel, perc = 0.05):\n",
    "        mi, ma = (np.percentile(channel, perc), np.percentile(channel,100.0-perc))\n",
    "        channel = np.uint8(np.clip((channel-mi)*255.0/(ma-mi), 0, 255))\n",
    "        return channel\n",
    "    img  = np.dstack([wb(channel, 0.05) for channel in cv2.split(img)])\n",
    "    #dullrazor\n",
    "    img = dullrazor(img)\n",
    "    plt.imshow(img)\n",
    "    plt.title(\"image après préprocessing\")\n",
    "    plt.show()\n",
    "    mask = getSegmentation(img).astype('uint8')\n",
    "    res = cv2.cvtColor(mask,cv2.COLOR_GRAY2RGB)\n",
    "    plt.imshow(mask)\n",
    "    plt.title(\"méthode 1\")\n",
    "    plt.show()\n",
    "    return img_to_array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess,\n",
    "    rescale = 1./255.,\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe = df[6:7],\n",
    "    directory = \"../input/siic-isic-224x224-images/train\", \n",
    "    x_col = \"filename\",\n",
    "    y_col=\"target\",\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False,\n",
    "    target_size = (CFG['img_size'], CFG['img_size']), \n",
    "    batch_size = CFG['batch_size'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On parcours toutes les images et on récupère les segmentations dans un tableau.\n",
    "#Enfin, on peut exporter ce tableau dans un fichier pickle, pour les etudier dans un autre notebook\n",
    "data_list = np.zeros((1,224,224,3))\n",
    "label_list = np.zeros((1,2))\n",
    "batch_index = 0\n",
    "\n",
    "while batch_index <= test_generator.batch_index:\n",
    "    data,label = test_generator.next()\n",
    "    data_list = np.vstack((data_list, data))\n",
    "    label_list = np.vstack((label_list, label))\n",
    "    batch_index = batch_index + 1\n",
    "    \n",
    "data_list = data_list[1:]\n",
    "label_list = label_list[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open('imgs3.pickle', 'wb') as handle:\n",
    "#     pickle.dump(data_list, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "# with open('labels3.pickle', 'wb') as handle:\n",
    "#     pickle.dump(df, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U NET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def BCDU_net_D3(input_size = (256,256,1)):\n",
    "    N = input_size[0]\n",
    "    img_input = Input(input_size)\n",
    "\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(img_input)\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "    drop3 = Dropout(0.5)(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    # D1\n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)     \n",
    "    conv4_1 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "    drop4_1 = Dropout(0.5)(conv4_1)\n",
    "    # D2\n",
    "    conv4_2 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(drop4_1)     \n",
    "    conv4_2 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4_2)\n",
    "    conv4_2 = Dropout(0.5)(conv4_2)\n",
    "    # D3\n",
    "    merge_dense = concatenate([conv4_2,drop4_1], axis = 3)\n",
    "    conv4_3 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge_dense)     \n",
    "    conv4_3 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4_3)\n",
    "    drop4_3 = Dropout(0.5)(conv4_3)\n",
    "\n",
    "    up6 = Conv2DTranspose(256, kernel_size=2, strides=2, padding='same',kernel_initializer = 'he_normal')(drop4_3)\n",
    "    up6 = BatchNormalization(axis=3)(up6)\n",
    "    up6 = Activation('relu')(up6)\n",
    "\n",
    "    x1 = Reshape(target_shape=(1, np.int32(N/4), np.int32(N/4), 256))(drop3)\n",
    "    x2 = Reshape(target_shape=(1, np.int32(N/4), np.int32(N/4), 256))(up6)\n",
    "    merge6  = concatenate([x1,x2], axis = 1) \n",
    "    merge6 = ConvLSTM2D(filters = 128, kernel_size=(3, 3), padding='same', return_sequences = False, go_backwards = True,kernel_initializer = 'he_normal')(merge6)\n",
    "\n",
    "    conv6 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "    conv6 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "\n",
    "    up7 = Conv2DTranspose(128, kernel_size=2, strides=2, padding='same',kernel_initializer = 'he_normal')(conv6)\n",
    "    up7 = BatchNormalization(axis=3)(up7)\n",
    "    up7 = Activation('relu')(up7)\n",
    "\n",
    "    x1 = Reshape(target_shape=(1, np.int32(N/2), np.int32(N/2), 128))(conv2)\n",
    "    x2 = Reshape(target_shape=(1, np.int32(N/2), np.int32(N/2), 128))(up7)\n",
    "    merge7  = concatenate([x1,x2], axis = 1) \n",
    "    merge7 = ConvLSTM2D(filters = 64, kernel_size=(3, 3), padding='same', return_sequences = False, go_backwards = True,kernel_initializer = 'he_normal' )(merge7)\n",
    "\n",
    "    conv7 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "    conv7 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "\n",
    "    up8 = Conv2DTranspose(64, kernel_size=2, strides=2, padding='same',kernel_initializer = 'he_normal')(conv7)\n",
    "    up8 = BatchNormalization(axis=3)(up8)\n",
    "    up8 = Activation('relu')(up8)    \n",
    "\n",
    "    x1 = Reshape(target_shape=(1, N, N, 64))(conv1)\n",
    "    x2 = Reshape(target_shape=(1, N, N, 64))(up8)\n",
    "    merge8  = concatenate([x1,x2], axis = 1) \n",
    "    merge8 = ConvLSTM2D(filters = 32, kernel_size=(3, 3), padding='same', return_sequences = False, go_backwards = True,kernel_initializer = 'he_normal' )(merge8)    \n",
    "\n",
    "    conv8 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "    conv8 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "    conv8 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "    conv9 = Conv2D(1, 1, activation = 'sigmoid')(conv8)\n",
    "\n",
    "    model = Model(img_input, conv9)\n",
    "    model.compile(optimizer=Adam(lr=1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = BCDU_net_D3(input_size = (256,256,3))#remettre 256 ?\n",
    "model.load_weights(\"../input/weightsbcdunetd3/bcdunet_melanoma.hdf5\")\n",
    "res = model.predict_generator(\n",
    "    test_generator\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
