{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Auteur: Antoine Cadiou\n",
    "\n",
    "# Attention: pour fonctionner il faut récupérer les données sur ces liens: \n",
    "### images: https://www.kaggle.com/arroqc/siic-isic-224x224-images\n",
    "### labels: https://www.kaggle.com/antocad/labels-siim-isic-224\n",
    "#### et changer les liens de données dans: 4ème Box L2,  6ème Box L34 & 44 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os, cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, array_to_img, img_to_array\n",
    "from tensorflow.keras import datasets\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from keras.regularizers import l2\n",
    "from keras import optimizers, layers, regularizers\n",
    "\n",
    "!pip install -U efficientnet\n",
    "!pip install tensor-dash\n",
    "import efficientnet.keras as efn\n",
    "from tensordash.tensordash import Tensordash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "CFG = dict(\n",
    "    DEVICE = 'GPU',\n",
    "    \n",
    "    train_size = 0.8,\n",
    "    random_seed = 42, #None ou int\n",
    "    \n",
    "    img_size = 224,\n",
    "    epochs = 100,\n",
    "    batch_size = 32,\n",
    "    \n",
    "    lr_start = 0.000006,\n",
    "    lr_max = 0.00000145,\n",
    "    lr_min = 0.000001,\n",
    "    lr_rampup = 5,\n",
    "    lr_sustain = 0,\n",
    "    lr_decay = 0.85,\n",
    "    optimizer = 'adam',\n",
    "    label_smooth_fac  =   0.05,\n",
    "    \n",
    "    net_count = 1,\n",
    "    tta_steps = 1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if CFG['DEVICE'] == \"TPU\":\n",
    "    print(\"connecting to TPU...\")\n",
    "    try:\n",
    "        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "        print('Running on TPU ', tpu.master())\n",
    "    except ValueError:\n",
    "        print(\"Could not connect to TPU\")\n",
    "        tpu = None\n",
    "\n",
    "    if tpu:\n",
    "        try:\n",
    "            print(\"initializing  TPU ...\")\n",
    "            tf.config.experimental_connect_to_cluster(tpu)\n",
    "            tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "            strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "            print(\"TPU initialized\")\n",
    "        except _:\n",
    "            print(\"failed to initialize TPU\")\n",
    "    else:\n",
    "        CFG['DEVICE'] = \"GPU\"\n",
    "\n",
    "if CFG['DEVICE'] != \"TPU\":\n",
    "    print(\"Using default strategy for CPU and single GPU\")\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "\n",
    "if CFG['DEVICE'] == \"GPU\":\n",
    "    print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "    \n",
    "\n",
    "AUTO     = tf.data.experimental.AUTOTUNE\n",
    "REPLICAS = strategy.num_replicas_in_sync\n",
    "print(f'REPLICAS: {REPLICAS}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#on lit les données csv\n",
    "train_original = pd.read_csv('../input/labels-siim-isic-224/train.csv', dtype=str)\n",
    "#on construit un dataframe réduit, plus équilibré\n",
    "part_true = train_original[train_original[\"target\"] == '1']\n",
    "part_false = train_original[train_original[\"target\"] == '0'].sample(len(part_true) * 3)\n",
    "train_balanced = pd.concat([part_true, part_false])\n",
    "#on shuffle les lignes du dataframe\n",
    "if CFG['random_seed']!=None:\n",
    "    np.random.seed(CFG['random_seed'])\n",
    "cols = train_balanced.columns\n",
    "idshuffle = np.arange(len(train_balanced))\n",
    "np.random.shuffle(idshuffle)\n",
    "df = pd.DataFrame(np.array(train_balanced)[idshuffle])\n",
    "df.columns = cols\n",
    "#on construit la colonne filename + nettoyage\n",
    "df['filename'] = df['image_name']+'.png'\n",
    "df['target'] = df['benign_malignant']\n",
    "df = df.drop(columns=['image_name', 'patient_id','sex','age_approx','anatom_site_general_challenge','diagnosis','benign_malignant'])\n",
    "df = df[['filename', 'target']]\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def view_images_crop(img, sigmaX=10):   \n",
    "    height, width, depth = img.shape    \n",
    "    x = int(width/2)\n",
    "    y = int(height/2)\n",
    "    r = np.amin((x,y))\n",
    "    circle_img = np.zeros((height, width), np.uint8)\n",
    "    cv2.circle(circle_img, (x,y), int(r), 1, thickness=-1)\n",
    "    img = cv2.bitwise_and(img, img, mask=circle_img)\n",
    "    img = cv2.addWeighted ( img,4, cv2.GaussianBlur( img , (0,0) , sigmaX) ,-4 ,128)\n",
    "    return img \n",
    "\n",
    "def view_images_bengraham(image):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "    image = cv2.addWeighted ( image,4, cv2.GaussianBlur( image , (0,0) , 256/10) ,-4 ,128)\n",
    "    return image\n",
    "\n",
    "def view_images_neuronengineer(image):\n",
    "    image = cv2.addWeighted ( image,4, cv2.GaussianBlur( image , (0,0) , 10) ,-4 ,128)\n",
    "    return image\n",
    "\n",
    "def dullrazor(img, lowbound=20, filterstruc=7, inpaintmat=3):\n",
    "    #grayscale\n",
    "    imgtmp1 = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    #applying a blackhat\n",
    "    filterSize =(filterstruc, filterstruc)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, filterSize) \n",
    "    imgtmp2 = cv2.morphologyEx(imgtmp1, cv2.MORPH_BLACKHAT, kernel)\n",
    "    #0=skin and 255=hair\n",
    "    ret, mask = cv2.threshold(imgtmp2, lowbound, 255, cv2.THRESH_BINARY)\n",
    "    #inpainting\n",
    "    img_final = cv2.inpaint(img, mask, inpaintmat ,cv2.INPAINT_TELEA)\n",
    "    return img_final\n",
    "\n",
    "def preprocess(input_img):\n",
    "    img = (input_img.copy()).astype('uint8')\n",
    "    #White Balancing\n",
    "    def wb(channel, perc = 0.05):\n",
    "        mi, ma = (np.percentile(channel, perc), np.percentile(channel,100.0-perc))\n",
    "        channel = np.uint8(np.clip((channel-mi)*255.0/(ma-mi), 0, 255))\n",
    "        return channel\n",
    "    img  = np.dstack([wb(channel, 0.05) for channel in cv2.split(img)])\n",
    "    #Hair removal\n",
    "    img = dullrazor(img)\n",
    "    #Crop view\n",
    "    img = view_images_crop(img)\n",
    "    return img_to_array(img)\n",
    "\n",
    "def focal_loss(alpha=0.25,gamma=2.0):\n",
    "    def focal_crossentropy(y_true, y_pred):\n",
    "        bce = K.binary_crossentropy(y_true, y_pred)\n",
    "        \n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1.- K.epsilon())\n",
    "        p_t = (y_true*y_pred) + ((1-y_true)*(1-y_pred))\n",
    "        \n",
    "        alpha_factor = 1\n",
    "        modulating_factor = 1\n",
    "\n",
    "        alpha_factor = y_true*alpha + ((1-alpha)*(1-y_true))\n",
    "        modulating_factor = K.pow((1-p_t), gamma)\n",
    "\n",
    "        # compute the final loss and return\n",
    "        return K.mean(alpha_factor*modulating_factor*bce, axis=-1)\n",
    "    return focal_crossentropy\n",
    "\n",
    "def getLearnRateCallback(cfg):\n",
    "    ''' Using callbacks for learning rate adjustments. '''\n",
    "    lr_max = cfg['lr_max'] * strategy.num_replicas_in_sync * cfg['batch_size']\n",
    "\n",
    "    def lrfn(epoch):\n",
    "        if epoch < cfg['lr_rampup']:\n",
    "            lr = (lr_max - cfg['lr_start']) / cfg['lr_rampup'] * epoch + cfg['lr_start']\n",
    "        elif epoch < cfg['lr_rampup'] + cfg['lr_sustain']:\n",
    "            lr = lr_max\n",
    "        else:\n",
    "            lr = (lr_max - cfg['lr_min']) * cfg['lr_decay']**(epoch - cfg['lr_rampup'] - cfg['lr_sustain']) + cfg['lr_min']\n",
    "        return lr\n",
    "\n",
    "    lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=True)\n",
    "    return lr_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def cross_val(CFG, df, batch_size, cv=5, name='model'):\n",
    "    l,c = df.shape\n",
    "    idx = np.arange(l)\n",
    "    np.random.shuffle(idx)\n",
    "    sizeFold = int(np.floor(l/cv))\n",
    "    scores = []\n",
    "    histories = []\n",
    "    models = []\n",
    "    for i in range(cv):\n",
    "        #CREER LES FOLDS\n",
    "        idxVal = idx[i*sizeFold : (i+1)*sizeFold]\n",
    "        idxTrain = np.ones(l)\n",
    "        idxTrain[idxVal] = 0\n",
    "        idxTrain = idx[idxTrain.astype('bool')]\n",
    "        df_train = df.iloc[idxTrain,:]\n",
    "        df_val = df.iloc[idxVal,:]\n",
    "        #CREER LES GENERATEURS DE DONNEES (lecture des images)\n",
    "        train_datagen = ImageDataGenerator(\n",
    "            rotation_range = 170,\n",
    "            zoom_range = 0.1,\n",
    "            width_shift_range = 0.1,\n",
    "            height_shift_range = 0.1,\n",
    "            horizontal_flip = True,\n",
    "            vertical_flip = True,\n",
    "            rescale = 1./255.,\n",
    "            #preprocessing_function = preprocess,\n",
    "        )\n",
    "        val_datagen = ImageDataGenerator(\n",
    "            rescale = 1./255.,\n",
    "            #preprocessing_function=preprocess,\n",
    "        )\n",
    "        train_generator = train_datagen.flow_from_dataframe(\n",
    "            dataframe = df_train, \n",
    "            directory = \"../input/siic-isic-224x224-images/train\", \n",
    "            x_col = \"filename\", \n",
    "            y_col = \"target\",\n",
    "            class_mode = \"categorical\", #\"binary\"\n",
    "            target_size = (CFG['img_size'],CFG['img_size']),\n",
    "            batch_size = batch_size,\n",
    "            validate_filenames = False,\n",
    "        )\n",
    "        val_generator = val_datagen.flow_from_dataframe(\n",
    "            dataframe = df_val,\n",
    "            directory = \"../input/siic-isic-224x224-images/train\", \n",
    "            x_col = \"filename\",\n",
    "            y_col = \"target\",\n",
    "            class_mode = \"categorical\", #\"binary\"\n",
    "            target_size = (CFG['img_size'],CFG['img_size']), \n",
    "            batch_size = batch_size,\n",
    "            validate_filenames = False,\n",
    "        )\n",
    "        #RECOMPILER UN MODELE\n",
    "        base_model = efn.EfficientNetB0(\n",
    "            weights='noisy-student',\n",
    "            include_top=False,\n",
    "            input_shape=(CFG['img_size'], CFG['img_size'], 3)\n",
    "        )\n",
    "        base_model.trainable = True\n",
    "        model = Sequential()\n",
    "        model.add(base_model)\n",
    "        model.add(layers.GlobalAveragePooling2D())\n",
    "        model.add(Dense(128, activation='relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dense(2, activation='softmax'))\n",
    "        losses = [tf.keras.losses.BinaryCrossentropy(label_smoothing = CFG['label_smooth_fac']), focal_loss]\n",
    "        callbacks = [getLearnRateCallback(CFG), \\\n",
    "                     tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5),\n",
    "                     tf.keras.callbacks.ModelCheckpoint(name+\"_\"+str(i)+\".h5\", save_best_only=True, monitor='val_auc', mode='max', save_weights_only=True)]\n",
    "        model.compile(optimizer=CFG['optimizer'],\n",
    "                      loss=losses,\n",
    "                      metrics=['accuracy', keras.metrics.AUC(name='auc')])\n",
    "        #FIT LE MODELE\n",
    "        history = model.fit_generator(\n",
    "            train_generator,\n",
    "            validation_data=val_generator,\n",
    "            epochs=CFG['epochs'],\n",
    "            validation_steps=len(df_val) // batch_size,\n",
    "            callbacks=callbacks,\n",
    "        )\n",
    "        histories.append(history)\n",
    "        models.append(model)\n",
    "        scores.append(history.history['val_auc'][-1])\n",
    "    return np.array(scores),histories,models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores,H,M = cross_val(CFG, df, batch_size=32, cv=5) #wop = without preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = np.argmax(scores)\n",
    "history = H[best]\n",
    "# loss\n",
    "plt.figure(figsize=(20,8))\n",
    "plt.plot(history.history['loss'],color=\"#F7728B\", label='loss', marker='.', linestyle='--')\n",
    "plt.plot(history.history['val_loss'], color=\"#3CA3EC\", label='validation loss', marker='.', linestyle='--')\n",
    "plt.legend(loc=\"upper right\",fancybox=True, framealpha=1, shadow=True, borderpad=1)\n",
    "plt.title(label=\"Loss & Validation Loss\")\n",
    "plt.grid()\n",
    "for i in range(len(history.history['loss'])):\n",
    "    yi = \"{:.3f}\".format(history.history['loss'][i])\n",
    "    yi2 = \"{:.3f}\".format(history.history['val_loss'][i])\n",
    "    s = str(yi)\n",
    "    s2 = str(yi2)\n",
    "    plt.text(i + 0.03, history.history['loss'][i] + 0.01, s)\n",
    "    plt.text(i + 0.03, history.history['val_loss'][i] + 0.01, s2)\n",
    "plt.show()\n",
    "# accuracy\n",
    "plt.figure(figsize=(20,8))\n",
    "plt.plot(history.history['accuracy'],color=\"#51B232\", label='accuracy', marker='.', linestyle='--')\n",
    "plt.plot(history.history['val_accuracy'], color=\"#CF8F32\", label='validation accuracy', marker='.', linestyle='--')\n",
    "plt.legend(loc='lower right',fancybox=True, framealpha=1, shadow=True, borderpad=1)\n",
    "plt.title(label=\"Accuracy & Validation Accuracy\")\n",
    "plt.grid()\n",
    "for i in range(len(history.history['accuracy'])):\n",
    "    yi = \"{:.3f}\".format(history.history['accuracy'][i])\n",
    "    yi2 = \"{:.3f}\".format(history.history['val_accuracy'][i])\n",
    "    s = str(yi)\n",
    "    s2 = str(yi2)\n",
    "    plt.text(i + 0.03, history.history['accuracy'][i] + 0.01, s)\n",
    "    plt.text(i + 0.03, history.history['val_accuracy'][i] + 0.01, s2)\n",
    "plt.show()\n",
    "# AUC\n",
    "plt.figure(figsize=(20,8))\n",
    "plt.plot(history.history['auc'],color=\"#51B232\", label='auc', marker='.', linestyle='--')\n",
    "plt.plot(history.history['val_auc'], color=\"#CF8F32\", label='validation auc', marker='.', linestyle='--')\n",
    "plt.legend(loc='lower right',fancybox=True, framealpha=1, shadow=True, borderpad=1)\n",
    "plt.title(label=\"AUC & Validation AUC\")\n",
    "plt.grid()\n",
    "for i in range(len(history.history['auc'])):\n",
    "    yi = \"{:.3f}\".format(history.history['auc'][i])\n",
    "    yi2 = \"{:.3f}\".format(history.history['val_auc'][i])\n",
    "    s = str(yi)\n",
    "    s2 = str(yi2)\n",
    "    plt.text(i + 0.03, history.history['auc'][i] + 0.01, s)\n",
    "    plt.text(i + 0.03, history.history['val_auc'][i] + 0.01, s2)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
